{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618eebea",
   "metadata": {},
   "source": [
    "# ìš°ìš¸ì¦ íŒë³„ì„ ìœ„í•œ ì–¼êµ´ í‘œì • ì´ì§„ ë¶„ë¥˜ ëª¨ë¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì£¼ì–´ì§„ ì–¼êµ´ í‘œì • ì´ë¯¸ì§€ë¥¼ ì´ìš©í•´ **ìš°ìš¸ì¦ ì—¬ë¶€**ë¥¼ íŒë³„í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ ëª¨ë¸ì„ ê°œë°œí•©ë‹ˆë‹¤. í”„ë¡œì íŠ¸ì˜ ìµœì¢… ëª©í‘œëŠ” `ë¶ˆì•ˆ(anxiety)`, `ìƒì²˜(hurt)`, `ìŠ¬í””(sadness)` ê°ì •ì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ \"ìš°ìš¸ ê´€ë ¨(1)\"ë¡œ, ê·¸ ì™¸ì˜ ê°ì •(`ë¶„ë…¸(anger)`, `ê¸°ì¨(joy)`, `ì¤‘ë¦½(neutral)`, `ë‹¹í™©(surprise)`)ì„ \"ë¹„ìš°ìš¸ ê´€ë ¨(0)\"ìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤:\n",
    "```\n",
    "data/\n",
    "  train/\n",
    "    train_image/        # í›ˆë ¨ ì´ë¯¸ì§€ í´ë” (ê°ì •ë³„ í•˜ìœ„ í´ë”)\n",
    "    train_label/        # í›ˆë ¨ ë¼ë²¨(JSON íŒŒì¼)\n",
    "  vali/\n",
    "    vali_image/         # ê²€ì¦ ì´ë¯¸ì§€ í´ë”\n",
    "    vali_label/         # ê²€ì¦ ë¼ë²¨(JSON íŒŒì¼)\n",
    "```\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” ì´ëŸ¬í•œ êµ¬ì¡°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ PyTorch ë°ì´í„°ì…‹ì„ ì •ì˜í•˜ê³ , ì´ë¯¸ì§€ ì „ì²˜ë¦¬/ì¦ê°•ì„ ìˆ˜í–‰í•˜ë©°, ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸(ResNet50)ì„ ë¯¸ì„¸ì¡°ì •(fine-tuning)í•˜ì—¬ ìš°ìš¸ì¦ ì—¬ë¶€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤. ì¤‘ê°„ ì¤‘ê°„ì— ê° ë‹¨ê³„ì˜ ê°œë…ì„ **ë°±ì§€ìƒíƒœì—ì„œ ì„¤ëª…í•˜ë“¯ì´ ì „ë¶€ ë¶„í•´í•´ì„œ ì„¤ëª…**í•˜ë©°, ì–´ë ¤ìš´ ìš©ì–´ëŠ” ë”°ë¡œ ì •ì˜í•©ë‹ˆë‹¤. ë˜í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ í•´ê²°í•˜ê¸° ìœ„í•´ **í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜(class weight)**ë¥¼ ì ìš©í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a17aed",
   "metadata": {},
   "source": [
    "## 1. íŒ¨í‚¤ì§€ ë¶ˆëŸ¬ì˜¤ê¸°ì™€ ê¸°ë³¸ ì„¤ì •\n",
    "\n",
    "ë¨¼ì € ëª¨ë¸ í•™ìŠµì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. PyTorch(`torch`), ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¥¼ ìœ„í•œ `torchvision`, ë°ì´í„° ë¶„ì„ì„ ìœ„í•œ `pandas`ì™€ `numpy`, ì‹œê°í™”ë¥¼ ìœ„í•œ `matplotlib` ë° ê¸°íƒ€ ìœ í‹¸ë¦¬í‹° íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. `device` ë³€ìˆ˜ëŠ” í•™ìŠµì„ GPUì—ì„œ ìˆ˜í–‰í•  ìˆ˜ ìˆë„ë¡ GPU(CUDA) ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **PyTorch(Torch)**: íŒŒì´ì¬ ê¸°ë°˜ì˜ ë”¥ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, í…ì„œ ì—°ì‚° ë° ìë™ ë¯¸ë¶„ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "- **torchvision**: ì´ë¯¸ì§€ ë°ì´í„°ì…‹ê³¼ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ë“¤ì„ ì œê³µí•˜ëŠ” PyTorchì˜ ì„œë¸ŒíŒ¨í‚¤ì§€ì…ë‹ˆë‹¤.\n",
    "- **numpy**: ë‹¤ì°¨ì› ë°°ì—´ ì—°ì‚°ì„ ìœ„í•œ ê¸°ë³¸ íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤.\n",
    "- **pandas**: í…Œì´ë¸” í˜•íƒœì˜ ë°ì´í„°ë¥¼ ë‹¤ë£¨ëŠ” ë° ìœ ìš©í•œ íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤.\n",
    "- **matplotlib**: ê·¸ë˜í”„ ê·¸ë¦¬ê¸°ë¥¼ ìœ„í•œ ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeb6eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ ì¥ì¹˜ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. GPUê°€ ìˆìœ¼ë©´ GPUë¥¼ ì‚¬ìš©í•˜ê³ , ì—†ìœ¼ë©´ CPUë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14857687",
   "metadata": {},
   "source": [
    "## 2. ê°ì • ë ˆì´ë¸” ì •ì˜\n",
    "\n",
    "ì£¼ì–´ì§„ ë°ì´í„°ëŠ” 7ê°œì˜ ê°ì • ë ˆì´ë¸”ì„ ê°–ìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì´ 7ê°œ ê°ì •ì„ **ìš°ìš¸ ê´€ë ¨(1)**ê³¼ **ë¹„ìš°ìš¸ ê´€ë ¨(0)** ë‘ ê°œì˜ í´ë˜ìŠ¤ë¡œ ì¬ë¶„ë¥˜í•©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•´ ê°ì •ë³„ë¡œ í•œêµ­ì–´ ë ˆì´ë¸”ê³¼ í•¨ê»˜ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ë¥¼ ì •ì˜í•˜ê³ , ìš°ìš¸ í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ê°ì • ëª©ë¡(`DEPRESSION_EMOTIONS`)ê³¼ ë¹„ìš°ìš¸ í´ë˜ìŠ¤ì— í•´ë‹¹í•˜ëŠ” ê°ì • ëª©ë¡(`NON_DEPRESSION_EMOTIONS`)ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "- **ë¶„ë…¸(anger)**, **ê¸°ì¨(joy)**, **ì¤‘ë¦½(neutral)**, **ë‹¹í™©(surprise)**: ë¹„ìš°ìš¸ ê´€ë ¨(0)\n",
    "- **ë¶ˆì•ˆ(anxiety)**, **ìƒì²˜(hurt)**, **ìŠ¬í””(sadness)**: ìš°ìš¸ ê´€ë ¨(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b46b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›ë³¸ ê°ì • ì´ë¦„ê³¼ í•œêµ­ì–´ í‘œê¸°ë¥¼ ë§¤í•‘í•©ë‹ˆë‹¤.\n",
    "EMOTIONS = {\n",
    "    'anger': 'ë¶„ë…¸',\n",
    "    'anxiety': 'ë¶ˆì•ˆ',\n",
    "    'hurt': 'ìƒì²˜',\n",
    "    'joy': 'ê¸°ì¨',\n",
    "    'neutral': 'ì¤‘ë¦½',\n",
    "    'sadness': 'ìŠ¬í””',\n",
    "    'surprise': 'ë‹¹í™©'\n",
    "}\n",
    "\n",
    "# ìš°ìš¸ê³¼ ë¹„ìš°ìš¸ í´ë˜ìŠ¤ë¥¼ ì§€ì •í•©ë‹ˆë‹¤.\n",
    "DEPRESSION_EMOTIONS = ['anxiety', 'hurt', 'sadness']  # ë ˆì´ë¸” 1\n",
    "NON_DEPRESSION_EMOTIONS = ['anger', 'joy', 'neutral', 'surprise']  # ë ˆì´ë¸” 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235c7552",
   "metadata": {},
   "source": [
    "## 3. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ì‘ì„±\n",
    "\n",
    "`torch.utils.data.Dataset`ì„ ìƒì†í•˜ì—¬ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤. ì´ í´ë˜ìŠ¤ëŠ” ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œì™€ ë¼ë²¨ ì •ë³´ë¥¼ ì½ì–´ì™€ì„œ `__getitem__` ë©”ì„œë“œì—ì„œ í•œ ìƒ˜í”Œì”© ë°˜í™˜í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "\n",
    "### 3.1 ë¼ë²¨ JSON íŒŒì‹±\n",
    "\n",
    "í›ˆë ¨/ê²€ì¦ ë°ì´í„°ì˜ ë ˆì´ë¸”ì€ ê°ê° JSON íŒŒì¼ë¡œ ì œê³µë©ë‹ˆë‹¤. ê° JSON íŒŒì¼ì—ëŠ” í•´ë‹¹ ê°ì • í´ë”ì˜ ì´ë¯¸ì§€ íŒŒì¼ ì´ë¦„ê³¼ í•¨ê»˜ ë¼ë²¨ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. íŒŒì‹± í•¨ìˆ˜ëŠ” í´ë” ë‚´ ëª¨ë“  JSONì„ ì½ì–´ ì´ë¯¸ì§€ ê²½ë¡œì™€ ê°ì •(í…ìŠ¤íŠ¸ ë ˆì´ë¸”)ì„ ëª¨ìœ¼ê³ , ì´ë¥¼ ìš°ìš¸/ë¹„ìš°ìš¸ ì´ì§„ ë¼ë²¨ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "### 3.2 ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°ì™€ ì „ì²˜ë¦¬\n",
    "\n",
    "PyTorchì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ë ¤ë©´ `PIL.Image` ëª¨ë“ˆì„ ì‚¬ìš©í•˜ê±°ë‚˜ `torchvision.io.read_image` ë“±ì„ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” `PIL.Image.open`ì„ ì‚¬ìš©í•œ í›„, ì§€ì •í•œ ì „ì²˜ë¦¬(transform)ë¥¼ ì ìš©í•©ë‹ˆë‹¤. ì „ì²˜ë¦¬ ê³¼ì •ì—ëŠ” ë‹¤ìŒì´ í¬í•¨ë©ë‹ˆë‹¤:\n",
    "\n",
    "1. **ë¦¬ì‚¬ì´ì¦ˆ(Resize)**: ëª¨ë“  ì´ë¯¸ì§€ë¥¼ 224Ã—224 í”½ì…€ë¡œ í†µì¼í•©ë‹ˆë‹¤.\n",
    "2. **ë°ì´í„° ì¦ê°•(Data Augmentation)**: í•™ìŠµ ë°ì´í„°ì— í•œí•´ ë¬´ì‘ìœ„ ì¢Œìš° ë’¤ì§‘ê¸°, ì•½ê°„ì˜ íšŒì „, ìƒ‰ì¡° ë³€í™˜ ë“±ìœ¼ë¡œ ëª¨ë¸ì˜ ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì…ë‹ˆë‹¤.\n",
    "3. **Tensor ë³€í™˜ê³¼ ì •ê·œí™”**: ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜í•˜ê³ , í”½ì…€ ê°’ì„ 0~1 ì‚¬ì´ë¡œ ìŠ¤ì¼€ì¼ë§í•©ë‹ˆë‹¤. ë˜í•œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì— ë§ëŠ” í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•´ ì •ê·œí™”í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b69bbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Cell 6ì˜ parse_label_files í•¨ìˆ˜ ìˆ˜ì •\n",
    "def parse_label_files(label_dir, image_dir):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ ë ˆì´ë¸” í´ë”ì—ì„œ ëª¨ë“  JSON íŒŒì¼ì„ ì½ì–´ ì´ë¯¸ì§€ ê²½ë¡œì™€ ìš°ìš¸/ë¹„ìš°ìš¸ ë ˆì´ë¸”ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    samples = []\n",
    "    json_files = sorted(glob(os.path.join(label_dir, '*.json')))\n",
    "\n",
    "    # ê¸°ì¡´ EMOTIONS ë”•ì…”ë„ˆë¦¬ë¥¼ ì—­ë°©í–¥ìœ¼ë¡œ ì‚¬ìš© (í•œêµ­ì–´ â†’ ì˜ì–´)\n",
    "    KOREAN_TO_ENGLISH = {v: k for k, v in EMOTIONS.items()}\n",
    "    \n",
    "    # ë””ë²„ê¹…ìš©\n",
    "    emotion_counts = {}\n",
    "    label_counts = {0: 0, 1: 0}\n",
    "\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        for item in data:\n",
    "            file_name = item['filename']\n",
    "            emotion_korean = item['faceExp_uploader']  # í•œêµ­ì–´ ê°ì •\n",
    "            emotion_english = KOREAN_TO_ENGLISH.get(emotion_korean, emotion_korean)  # ì˜ì–´ë¡œ ë³€í™˜\n",
    "            \n",
    "            # ì´ë¯¸ì§€ ê²½ë¡œ êµ¬ì„± (í´ë”ëª…ì€ ì˜ì–´)\n",
    "            img_path = os.path.join(image_dir, emotion_english, file_name)\n",
    "            \n",
    "            # ìš°ìš¸ ê´€ë ¨ ê°ì •ì€ 1, ë¹„ìš°ìš¸ì€ 0\n",
    "            label = 1 if emotion_english in DEPRESSION_EMOTIONS else 0\n",
    "            samples.append((img_path, label))\n",
    "            \n",
    "            # ë””ë²„ê¹…ìš© ì¹´ìš´íŠ¸\n",
    "            emotion_counts[emotion_korean] = emotion_counts.get(emotion_korean, 0) + 1\n",
    "            label_counts[label] += 1\n",
    "\n",
    "    # ë””ë²„ê¹… ì •ë³´ ì¶œë ¥\n",
    "    print(\"ğŸ” ë°œê²¬ëœ ê°ì •ë³„ ê°œìˆ˜:\")\n",
    "    for emotion_kr, count in emotion_counts.items():\n",
    "        emotion_en = KOREAN_TO_ENGLISH.get(emotion_kr, emotion_kr)\n",
    "        label = 1 if emotion_en in DEPRESSION_EMOTIONS else 0\n",
    "        print(f\"  {emotion_kr} â†’ {emotion_en}: {count:,}ê°œ â†’ ë ˆì´ë¸” {label}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š ìµœì¢… ë ˆì´ë¸” ë¶„í¬:\")\n",
    "    print(f\"  ë¹„ìš°ìš¸(0): {label_counts[0]:,}ê°œ\")\n",
    "    print(f\"  ìš°ìš¸(1): {label_counts[1]:,}ê°œ\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21643b1",
   "metadata": {},
   "source": [
    "## 4. ë°ì´í„° ì „ì²˜ë¦¬(ë³€í™˜) ì •ì˜\n",
    "\n",
    "`torchvision.transforms`ë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµìš©ê³¼ ê²€ì¦ìš© ì „ì²˜ë¦¬ë¥¼ ê°ê° ì •ì˜í•©ë‹ˆë‹¤. í•™ìŠµ ë°ì´í„°ì—ëŠ” ë°ì´í„° ì¦ê°•ì„ í¬í•¨í•˜ê³ , ê²€ì¦ ë°ì´í„°ì—ëŠ” ë¦¬ì‚¬ì´ì¦ˆì™€ í…ì„œ ë³€í™˜ë§Œ ì ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **RandomHorizontalFlip**: 50% í™•ë¥ ë¡œ ì´ë¯¸ì§€ë¥¼ ì¢Œìš°ë¡œ ë’¤ì§‘ì–´ ëª¨ë¸ì´ ì¢Œìš° ëŒ€ì¹­ì— ëœ ë¯¼ê°í•˜ë„ë¡ í•©ë‹ˆë‹¤.\n",
    "- **RandomRotation**: Â±10ë„ ë²”ìœ„ì—ì„œ ì´ë¯¸ì§€ë¥¼ íšŒì „ì‹œì¼œ ë‹¤ì–‘í•œ ê°ë„ì˜ ì–¼êµ´ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "- **ColorJitter**: ë°ê¸°, ëŒ€ë¹„, ì±„ë„, ìƒ‰ì¡°ë¥¼ ëœë¤í•˜ê²Œ ì¡°ì •í•˜ì—¬ ì¡°ëª… ë³€í™”ì— ê²¬ë”œ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.\n",
    "- **Resize**: ì…ë ¥ ì´ë¯¸ì§€ë¥¼ 224Ã—224 í”½ì…€ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.\n",
    "- **ToTensor**: `PIL.Image`ë¥¼ `[0, 1]` ë²”ìœ„ì˜ PyTorch í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
    "- **Normalize**: ì´ë¯¸ì§€ì˜ í”½ì…€ ê°’ì„ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”í•˜ì—¬ í•™ìŠµì„ ì•ˆì •í™”í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ImageNet ë°ì´í„°ì…‹ì—ì„œ í•™ìŠµëœ ì‚¬ì „ í•™ìŠµ ëª¨ë¸ê³¼ ë™ì¼í•œ í†µê³„ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4aac8921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    ì–¼êµ´ ì´ë¯¸ì§€ì™€ ìš°ìš¸/ë¹„ìš°ìš¸ ë ˆì´ë¸”ì„ í¬í•¨í•˜ëŠ” ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    def __init__(self, samples, transform=None):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58457b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet í†µê³„ (ì‚¬ì „ í•™ìŠµ ëª¨ë¸ê³¼ í˜¸í™˜)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "vali_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60c88e2",
   "metadata": {},
   "source": [
    "## 5. ë°ì´í„°ì…‹ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±ê³¼ í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬\n",
    "\n",
    "### 5.1 ë°ì´í„°ì…‹ ë¡œë”©\n",
    "ì•ì„œ ì •ì˜í•œ `parse_label_files` í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í›ˆë ¨ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„°ì˜ (ì´ë¯¸ì§€ ê²½ë¡œ, ë¼ë²¨) ë¦¬ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì‹¤ì œ ê²½ë¡œëŠ” í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, `train_label_dir`ëŠ” `data/train/train_label` í´ë”ì˜ ê²½ë¡œì´ê³ , `train_image_dir`ëŠ” `data/train/train_image` í´ë”ì˜ ê²½ë¡œì…ë‹ˆë‹¤.\n",
    "\n",
    "### 5.2 í´ë˜ìŠ¤ ë¶ˆê· í˜•(imbalance) ë¬¸ì œ\n",
    "ê°ì • ë°ì´í„°ì˜ ë¶„í¬ê°€ ê· ì¼í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì—, ìš°ìš¸/ë¹„ìš°ìš¸ ë ˆì´ë¸”ì˜ ë¹„ìœ¨ë„ ë¶ˆê· í˜•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê° í´ë˜ìŠ¤ì˜ **ê°€ì¤‘ì¹˜(weights)**ë¥¼ ê³„ì‚°í•˜ì—¬ ì†ì‹¤ í•¨ìˆ˜ì— ì ìš©í•˜ê±°ë‚˜, `WeightedRandomSampler`ë¥¼ ì‚¬ìš©í•˜ì—¬ ê° ë°°ì¹˜ì—ì„œ í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ê· í˜• ìˆê²Œ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ì—ì„œëŠ” ê° í´ë˜ìŠ¤ì˜ ìƒ˜í”Œ ìˆ˜ë¥¼ ì„¸ì–´ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ê³„ì‚°í•˜ê³ , í•´ë‹¹ ê°€ì¤‘ì¹˜ë¥¼ `WeightedRandomSampler`ì— ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5177b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ë°œê²¬ëœ ê°ì •ë³„ ê°œìˆ˜:\n",
      "  ê¸°ì¨ â†’ joy: 60,103ê°œ â†’ ë ˆì´ë¸” 0\n",
      "  ë‹¹í™© â†’ surprise: 59,643ê°œ â†’ ë ˆì´ë¸” 0\n",
      "  ë¶„ë…¸ â†’ anger: 59,696ê°œ â†’ ë ˆì´ë¸” 0\n",
      "  ë¶ˆì•ˆ â†’ anxiety: 59,262ê°œ â†’ ë ˆì´ë¸” 1\n",
      "  ìƒì²˜ â†’ hurt: 59,389ê°œ â†’ ë ˆì´ë¸” 1\n",
      "  ìŠ¬í”” â†’ sadness: 59,841ê°œ â†’ ë ˆì´ë¸” 1\n",
      "  ì¤‘ë¦½ â†’ neutral: 59,233ê°œ â†’ ë ˆì´ë¸” 0\n",
      "\n",
      "ğŸ“Š ìµœì¢… ë ˆì´ë¸” ë¶„í¬:\n",
      "  ë¹„ìš°ìš¸(0): 238,675ê°œ\n",
      "  ìš°ìš¸(1): 178,492ê°œ\n",
      "ğŸ” ë°œê²¬ëœ ê°ì •ë³„ ê°œìˆ˜:\n",
      "  ê¸°ì¨ â†’ joy: 7,499ê°œ â†’ ë ˆì´ë¸” 0\n",
      "  ë‹¹í™© â†’ surprise: 7,454ê°œ â†’ ë ˆì´ë¸” 0\n",
      "  ë¶„ë…¸ â†’ anger: 7,461ê°œ â†’ ë ˆì´ë¸” 0\n",
      "  ë¶ˆì•ˆ â†’ anxiety: 7,407ê°œ â†’ ë ˆì´ë¸” 1\n",
      "  ìƒì²˜ â†’ hurt: 7,423ê°œ â†’ ë ˆì´ë¸” 1\n",
      "  ìŠ¬í”” â†’ sadness: 7,479ê°œ â†’ ë ˆì´ë¸” 1\n",
      "  ì¤‘ë¦½ â†’ neutral: 7,403ê°œ â†’ ë ˆì´ë¸” 0\n",
      "\n",
      "ğŸ“Š ìµœì¢… ë ˆì´ë¸” ë¶„í¬:\n",
      "  ë¹„ìš°ìš¸(0): 29,817ê°œ\n",
      "  ìš°ìš¸(1): 22,309ê°œ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ë¹„ìš°ìš¸(0)': 238675, 'ìš°ìš¸(1)': 178492}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì • (ì‹¤ì œ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •í•˜ì„¸ìš”)\n",
    "base_dir = 'data'  # ì˜ˆ: C:/aug-08month_project5/hwa_in/data\n",
    "train_label_dir = os.path.join(base_dir, 'train', 'train_label')\n",
    "train_image_dir = os.path.join(base_dir, 'train', 'train_image')\n",
    "vali_label_dir = os.path.join(base_dir, 'vali', 'vali_label')\n",
    "vali_image_dir = os.path.join(base_dir, 'vali', 'vali_image')\n",
    "\n",
    "# ë ˆì´ë¸” íŒŒì¼ì—ì„œ (ê²½ë¡œ, ë¼ë²¨) ëª©ë¡ ì¶”ì¶œ\n",
    "train_samples = parse_label_files(train_label_dir, train_image_dir)\n",
    "vali_samples = parse_label_files(vali_label_dir, vali_image_dir)\n",
    "\n",
    "# ë°ì´í„°ì…‹ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "train_dataset = EmotionDataset(train_samples, transform=train_transform)\n",
    "vali_dataset = EmotionDataset(vali_samples, transform=vali_transform)\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ê³ ë ¤í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "labels = [label for _, label in train_samples]\n",
    "class_sample_count = np.bincount(labels)\n",
    "# í´ë˜ìŠ¤ê°€ 0 ë˜ëŠ” 1ë§Œ ì¡´ì¬í•œë‹¤ê³  ê°€ì •\n",
    "# ì•ˆì „í•œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "if len(class_sample_count) == 1:\n",
    "    # í•˜ë‚˜ì˜ í´ë˜ìŠ¤ë§Œ ìˆëŠ” ê²½ìš°\n",
    "    class_weights = np.array([1.0, 1.0])  # ë‘ í´ë˜ìŠ¤ ëª¨ë‘ ë™ì¼í•œ ê°€ì¤‘ì¹˜\n",
    "else:\n",
    "    class_weights = 1. / (class_sample_count + 1e-8)  # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€\n",
    "sample_weights = [class_weights[label] for label in labels]\n",
    "\n",
    "# WeightedRandomSampler ìƒì„±: ë°°ì¹˜ë§ˆë‹¤ í´ë˜ìŠ¤ê°€ ê· í˜• ìˆê²Œ ì¶”ì¶œë˜ë„ë¡ ë„ì™€ì¤Œ\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "batch_size = 32  # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ì¡°ì ˆ\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler, num_workers=4)\n",
    "vali_loader = DataLoader(vali_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¹„ìœ¨ ì¶œë ¥ (í™•ì¸ìš©)\n",
    "if len(class_sample_count) == 1:\n",
    "    class_counts = { 'ë¹„ìš°ìš¸(0)': int(class_sample_count[0]), 'ìš°ìš¸(1)': 0 }\n",
    "else:\n",
    "    class_counts = { 'ë¹„ìš°ìš¸(0)': int(class_sample_count[0]), 'ìš°ìš¸(1)': int(class_sample_count[1]) }\n",
    "\n",
    "class_counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58d0807",
   "metadata": {},
   "source": [
    "## 6. ëª¨ë¸ ì •ì˜ì™€ ì†ì‹¤ í•¨ìˆ˜ ì„¤ì •\n",
    "\n",
    "ë”¥ëŸ¬ë‹ ëª¨ë¸ë¡œëŠ” **ResNet50**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ResNet(Residual Network)ì€ ê¹Šì€ ì‹ ê²½ë§ì—ì„œ í•™ìŠµì´ ì–´ë ¤ì›Œì§€ëŠ” ë¬¸ì œë¥¼ ì”ì°¨ ì—°ê²°(residual connection)ë¡œ í•´ê²°í•œ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤. ì‚¬ì „ í•™ìŠµ(pretrained)ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¨ ë’¤, ë§ˆì§€ë§‰ ì™„ì „ì—°ê²°ì¸µ(fc)ì„ ìš°ë¦¬ì˜ ì´ì§„ ë¶„ë¥˜ ê³¼ì œì— ë§ê²Œ ìˆ˜ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì‚¬ì „ í•™ìŠµ(pretrained)**: ëŒ€ê·œëª¨ ë°ì´í„°ì…‹(ImageNet)ì—ì„œ ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì´ˆê¸°ê°’ìœ¼ë¡œ ì‚¬ìš©í•¨ìœ¼ë¡œì¨, ì ì€ ë°ì´í„°ì—ì„œë„ ë” ë¹ ë¥¸ ìˆ˜ë ´ê³¼ ë†’ì€ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "- **`nn.CrossEntropyLoss`**: ì†Œí”„íŠ¸ë§¥ìŠ¤(softmax)ì™€ ìŒì˜ ë¡œê·¸ìš°ë„ ì†ì‹¤ì„ ê²°í•©í•œ ì†ì‹¤ í•¨ìˆ˜ë¡œ, ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ì™€ 2ì§„ ë¶„ë¥˜ ëª¨ë‘ì— ì‚¬ìš©ë©ë‹ˆë‹¤. í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ì™„í™”í•˜ê¸° ìœ„í•´ `weight` ì¸ìë¡œ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ ì „ë‹¬í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a7a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‚¬ì „ í•™ìŠµëœ ResNet50 ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# ë§ˆì§€ë§‰ ì™„ì „ì—°ê²°ì¸µì˜ ì…ë ¥ íŠ¹ì§• ìˆ˜ë¥¼ êµ¬í•¨\n",
    "num_ftrs = model.fc.in_features\n",
    "# 2ê°œ í´ë˜ìŠ¤(ìš°ìš¸/ë¹„ìš°ìš¸)ì— ë§ê²Œ ì¶œë ¥ ë‰´ëŸ° ìˆ˜ë¥¼ ë³€ê²½\n",
    "model.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "# ëª¨ë¸ì„ GPU/CPUì— í• ë‹¹\n",
    "model = model.to(device)\n",
    "\n",
    "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ë¥¼ í…ì„œë¡œ ë³€í™˜í•˜ì—¬ ì†ì‹¤ í•¨ìˆ˜ì— ì „ë‹¬\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì € ì„¤ì • (Adam ì‚¬ìš©)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09670ef",
   "metadata": {},
   "source": [
    "## 7. í•™ìŠµê³¼ ê²€ì¦ ë£¨í”„ ì •ì˜\n",
    "\n",
    "ëª¨ë¸ í•™ìŠµì€ ì—¬ëŸ¬ ì—í­(epoch) ë™ì•ˆ í›ˆë ¨ ë°ì´í„° ì „ì²´ë¥¼ ë°˜ë³µí•˜ë©´ì„œ ìˆ˜í–‰ë©ë‹ˆë‹¤. ê° ì—í­ë§ˆë‹¤ í›ˆë ¨ ì†ì‹¤ê³¼ ì •í™•ë„, ê²€ì¦ ì†ì‹¤ê³¼ ì •í™•ë„ë¥¼ ê¸°ë¡í•˜ì—¬ ëª¨ë¸ì˜ ì„±ëŠ¥ ë³€í™”ë¥¼ ëª¨ë‹ˆí„°ë§í•©ë‹ˆë‹¤. ì—í­ì´ ì§„í–‰ë ìˆ˜ë¡ ê²€ì¦ ì†ì‹¤ì´ ê°ì†Œí•˜ê³  ì •í™•ë„ê°€ ì¦ê°€í•˜ë©´ ëª¨ë¸ì´ ì˜ í•™ìŠµë˜ê³  ìˆë‹¤ëŠ” ì‹ í˜¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "### ì£¼ìš” ìš©ì–´ ì„¤ëª…\n",
    "- **ì—í­(epoch)**: í›ˆë ¨ ë°ì´í„°ì…‹ ì „ì²´ë¥¼ í•œ ë²ˆ í†µê³¼í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "- **ë°°ì¹˜(batch)**: ì „ì²´ ë°ì´í„°ì…‹ì„ ì‘ê²Œ ë‚˜ëˆˆ ë¬¶ìŒì…ë‹ˆë‹¤. í•œ ë²ˆì— ë©”ëª¨ë¦¬ì— ì˜¬ë ¤ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ì˜ ì–‘ì…ë‹ˆë‹¤.\n",
    "- **ì •ë°©í–¥ íŒ¨ìŠ¤(forward pass)**: ì…ë ¥ ë°ì´í„°ë¥¼ ëª¨ë¸ì— í†µê³¼ì‹œì¼œ ì˜ˆì¸¡ê°’ì„ ì–»ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "- **ì—­ë°©í–¥ íŒ¨ìŠ¤(backpropagation)**: ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•œ ì†ì‹¤ì„ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ ë¯¸ë¶„ì„ ìˆ˜í–‰í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "- **ì˜µí‹°ë§ˆì´ì €(optimizer)**: ê³„ì‚°ëœ ê¸°ìš¸ê¸°(gradient)ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” Adamì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741438af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì„¤ì • (Dropout, BatchNorm ë“±ì´ í™œì„±í™”)\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ì •ë°©í–¥ íŒ¨ìŠ¤\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # ì˜ˆì¸¡ ê²°ê³¼\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # ì—­ë°©í–¥ íŒ¨ìŠ¤\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # í†µê³„ ì—…ë°ì´íŠ¸\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = running_corrects.double() / total\n",
    "    return epoch_loss, epoch_acc.item()\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()  # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì • (Dropout, BatchNorm ë¹„í™œì„±)\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "\n",
    "    # í‰ê°€ ì‹œì—ëŠ” ê¸°ìš¸ê¸° ê³„ì‚°ì„ í•˜ì§€ ì•ŠìŒ\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = running_corrects.double() / total\n",
    "    return epoch_loss, epoch_acc.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28841cb",
   "metadata": {},
   "source": [
    "## 8. ëª¨ë¸ í•™ìŠµ ì‹¤í–‰\n",
    "\n",
    "ìœ„ì—ì„œ ì •ì˜í•œ í•¨ìˆ˜ë“¤ì„ ì´ìš©í•´ ëª¨ë¸ì„ ì—¬ëŸ¬ ì—í­ ë™ì•ˆ í•™ìŠµí•©ë‹ˆë‹¤. ê° ì—í­ë§ˆë‹¤ í›ˆë ¨ ì†ì‹¤/ì •í™•ë„ì™€ ê²€ì¦ ì†ì‹¤/ì •í™•ë„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤. ì—í­ ìˆ˜(`num_epochs`)ëŠ” í”„ë¡œì íŠ¸ ìš”êµ¬ì‚¬í•­ê³¼ ì‹œê°„ì— ë”°ë¼ ì¡°ì ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ˆê¸°ì—ëŠ” 5~10 ì—í­ ì •ë„ë¡œ ì‹œì‘í•œ ë’¤, ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë³´ë©° ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6de1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10  # í•„ìš”ì— ë”°ë¼ ì¡°ì ˆ\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    vali_loss, vali_acc = evaluate(model, vali_loader, criterion, device)\n",
    "\n",
    "    print(f'Epoch {epoch}/{num_epochs}: ',\n",
    "          f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%',\n",
    "          f'| Val Loss: {vali_loss:.4f}, Val Acc: {vali_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19879abf",
   "metadata": {},
   "source": [
    "## 9. ì˜ˆì¸¡ ë° í˜¼ë™ í–‰ë ¬ ì‹œê°í™”\n",
    "\n",
    "í•™ìŠµì´ ì™„ë£Œëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì¡°ê¸ˆ ë” ìì„¸íˆ ë¶„ì„í•˜ê¸° ìœ„í•´ ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ í˜¼ë™ í–‰ë ¬(confusion matrix)ì„ ì‹œê°í™”í•©ë‹ˆë‹¤. í˜¼ë™ í–‰ë ¬ì€ ê° í´ë˜ìŠ¤(ì—¬ê¸°ì„œëŠ” ìš°ìš¸/ë¹„ìš°ìš¸)ì— ëŒ€í•´ ëª¨ë¸ì´ ì–¼ë§ˆë‚˜ ì •í™•íˆ ì˜ˆì¸¡í–ˆëŠ”ì§€ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
    "\n",
    "- **True Positive (TP)**: ì‹¤ì œ ìš°ìš¸ ìƒ˜í”Œì„ ìš°ìš¸ë¡œ ì •í™•íˆ ì˜ˆì¸¡í•œ ê²½ìš°\n",
    "- **False Positive (FP)**: ì‹¤ì œ ë¹„ìš°ìš¸ ìƒ˜í”Œì„ ìš°ìš¸ë¡œ ì˜ëª» ì˜ˆì¸¡í•œ ê²½ìš°\n",
    "- **True Negative (TN)**: ì‹¤ì œ ë¹„ìš°ìš¸ ìƒ˜í”Œì„ ë¹„ìš°ìš¸ë¡œ ì •í™•íˆ ì˜ˆì¸¡í•œ ê²½ìš°\n",
    "- **False Negative (FN)**: ì‹¤ì œ ìš°ìš¸ ìƒ˜í”Œì„ ë¹„ìš°ìš¸ë¡œ ì˜ëª» ì˜ˆì¸¡í•œ ê²½ìš°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f24cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds, labels=[0, 1])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['ë¹„ìš°ìš¸', 'ìš°ìš¸'])\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix (Validation Set)')\n",
    "    plt.show()\n",
    "\n",
    "# í˜¼ë™ í–‰ë ¬ ì¶œë ¥ (í•™ìŠµ ì™„ë£Œ í›„ ì‹¤í–‰)\n",
    "# plot_confusion_matrix(model, vali_loader, device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e0d49e",
   "metadata": {},
   "source": [
    "## 10. Grad-CAMì„ ì´ìš©í•œ ì‹œê°í™”\n",
    "\n",
    "ëª¨ë¸ì´ ì´ë¯¸ì§€ì˜ ì–´ëŠ ë¶€ë¶„ì— ì£¼ëª©í•˜ì—¬ ìš°ìš¸/ë¹„ìš°ìš¸ì„ íŒë‹¨í•˜ëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ í™•ì¸í•˜ê¸° ìœ„í•´ **Grad-CAM**(Gradient-weighted Class Activation Mapping)ì„ ì ìš©í•©ë‹ˆë‹¤. Grad-CAMì€ íŠ¹ì • í´ë˜ìŠ¤ì— ëŒ€í•œ ì¶œë ¥ì„ ê¸°ì¤€ìœ¼ë¡œ ë§ˆì§€ë§‰ í•©ì„±ê³± ì¸µì˜ íŠ¹ì„±ë§µ(feature map)ê³¼ ê·¸ë¼ë””ì–¸íŠ¸ë¥¼ ê²°í•©í•˜ì—¬ ì¤‘ìš” ì˜ì—­ì„ ê°•ì¡°í•œ íˆíŠ¸ë§µì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì•„ë˜ ì½”ë“œì—ì„œëŠ” ResNet50ì˜ ë§ˆì§€ë§‰ í•©ì„±ê³± ì¸µì¸ `model.layer4`ì— í›„í¬(hook)ë¥¼ ë“±ë¡í•˜ì—¬ forward íŒ¨ìŠ¤ì—ì„œì˜ feature mapê³¼ backward íŒ¨ìŠ¤ì—ì„œì˜ gradientë¥¼ ì €ì¥í•œ ë’¤, ì´ë¥¼ ì´ìš©í•´ íˆíŠ¸ë§µì„ ìƒì„±í•˜ê³  ì›ë³¸ ì´ë¯¸ì§€ ìœ„ì— ì˜¤ë²„ë ˆì´í•©ë‹ˆë‹¤. ê²€ì¦ ë°ì´í„°ì˜ ì²« ë²ˆì§¸ ìƒ˜í”Œì„ ì˜ˆì‹œë¡œ ì‚¬ìš©í•˜ì§€ë§Œ, ì›í•˜ëŠ” ë‹¤ë¥¸ ì´ë¯¸ì§€ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bda6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_gradcam(model, input_tensor, target_class):\n",
    "    model.eval()\n",
    "    feature_maps = []\n",
    "    gradients = []\n",
    "\n",
    "    def forward_hook(module, input, output):\n",
    "        feature_maps.append(output.detach())\n",
    "    def backward_hook(module, grad_in, grad_out):\n",
    "        gradients.append(grad_out[0].detach())\n",
    "    \n",
    "    # ë§ˆì§€ë§‰ í•©ì„±ê³± ì¸µ(layer4)ì— í›„í¬ ë“±ë¡\n",
    "    handle_f = model.layer4.register_forward_hook(forward_hook)\n",
    "    handle_b = model.layer4.register_backward_hook(backward_hook)\n",
    "\n",
    "    # forward pass\n",
    "    output = model(input_tensor.unsqueeze(0))\n",
    "    score = output[0, target_class]\n",
    "    # backward pass\n",
    "    model.zero_grad()\n",
    "    score.backward()\n",
    "\n",
    "    # í›„í¬ í•´ì œ\n",
    "    handle_f.remove()\n",
    "    handle_b.remove()\n",
    "\n",
    "    # gradientsì™€ feature_mapsëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥ë˜ë¯€ë¡œ ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©\n",
    "    grads = gradients[0][0]  # shape: [C, H, W]\n",
    "    fmap = feature_maps[0][0]  # shape: [C, H, W]\n",
    "\n",
    "    # ê° ì±„ë„ë³„ë¡œ gradientë¥¼ í‰ê· ë‚´ì–´ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "    weights = grads.mean(dim=(1, 2))\n",
    "    cam = torch.zeros(fmap.shape[1:], dtype=fmap.dtype).to(fmap.device)\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * fmap[i]\n",
    "    \n",
    "    cam = torch.relu(cam)\n",
    "    cam = cam - cam.min()\n",
    "    cam = cam / (cam.max() + 1e-8)\n",
    "    cam = cam.cpu().numpy()\n",
    "    # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ\n",
    "    cam = np.array(Image.fromarray(cam).resize((input_tensor.size(2), input_tensor.size(1))))\n",
    "    return cam\n",
    "\n",
    "\n",
    "def show_gradcam_on_image(input_tensor, cam_mask, mean=IMAGENET_MEAN, std=IMAGENET_STD):\n",
    "    # ì…ë ¥ ì´ë¯¸ì§€ëŠ” ì •ê·œí™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ ì›ë˜ ìŠ¤ì¼€ì¼ë¡œ ë˜ëŒë¦¼\n",
    "    img = input_tensor.cpu().permute(1,2,0).numpy()\n",
    "    img = img * np.array(std)[None, None, :] + np.array(mean)[None, None, :]\n",
    "    img = np.clip(img, 0, 1)\n",
    "    \n",
    "    heatmap = cm.jet(cam_mask)[..., :3]  # RGBA ì¤‘ RGBë§Œ\n",
    "    # íˆíŠ¸ë§µê³¼ ì›ë³¸ ì´ë¯¸ì§€ í•©ì„±\n",
    "    overlay = heatmap * 0.4 + img\n",
    "    overlay = overlay / overlay.max()\n",
    "    \n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('Original')\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title('Grad-CAM Overlay')\n",
    "    plt.imshow(overlay)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ì˜ˆì‹œ: ê²€ì¦ ë°ì´í„° ì²« ë²ˆì§¸ ìƒ˜í”Œì— Grad-CAM ì ìš©\n",
    "test_iter = iter(vali_loader)\n",
    "example_inputs, example_labels = next(test_iter)\n",
    "example_input = example_inputs[0].to(device)\n",
    "example_label = example_labels[0].item()\n",
    "\n",
    "# Grad-CAM ìƒì„±\n",
    "cam_mask = generate_gradcam(model, example_input, example_label)\n",
    "# ì‹œê°í™”\n",
    "show_gradcam_on_image(example_input.cpu(), cam_mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
